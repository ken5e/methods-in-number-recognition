{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNForNumberRecognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPL_mFSt3Ri7"
      },
      "source": [
        "# Import Tensorflow 2.0\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import layers, models\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data() #Y : name of the number ; X : picture of that number in 28x28"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DWq1lrJ_zsW"
      },
      "source": [
        "#%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbUKDaYQ41Og",
        "outputId": "03f3866d-9106-4519-b70d-9350fcb16643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0\n",
        "X_train = tf.expand_dims(X_train, -1)\n",
        "X_test = tf.expand_dims(X_test, -1)\n",
        "print(tf.shape(X_train))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([60000    28    28     1], shape=(4,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rljspY3k2-oM",
        "outputId": "c32b9fab-aeb2-4b29-d26d-1dc0ef1b219c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (4, 4), strides = 1, activation='relu', input_shape=(28, 28,1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10))\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 25, 25, 32)        544       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 10, 10, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                102464    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 122,154\n",
            "Trainable params: 122,154\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22B16_nJmiEf",
        "outputId": "c4f036ef-a758-480f-f354-badee9b6ffed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs=10, \n",
        "                    validation_data=(X_test, Y_test))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1360 - accuracy: 0.9583 - val_loss: 0.0437 - val_accuracy: 0.9851\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0448 - accuracy: 0.9862 - val_loss: 0.0290 - val_accuracy: 0.9898\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0324 - accuracy: 0.9899 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 0.0264 - val_accuracy: 0.9910\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.0265 - val_accuracy: 0.9921\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.0255 - val_accuracy: 0.9916\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.0329 - val_accuracy: 0.9907\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.0286 - val_accuracy: 0.9918\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.0364 - val_accuracy: 0.9897\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0356 - val_accuracy: 0.9900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2QOx61wquH8",
        "outputId": "fc93ac4c-03cd-491d-a057-b30a8524cb42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "  import numpy as np\n",
        "  data = tf.expand_dims(X_test[30], 0)\n",
        "  prediction = model.predict(data)\n",
        "\n",
        "  if np.argmax(prediction[0]) == Y_test[30]:\n",
        "    no = str(Y_test[30])\n",
        "    img = tf.squeeze(X_test[30], [2])\n",
        "    imgplot = plt.imshow(img)\n",
        "    print(f'prediction:{no}')\n",
        "  else:\n",
        "    print('cannot do')\n",
        "  \n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction:3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgAohDPqm3GK"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}